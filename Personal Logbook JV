Logbook Juan Valencia:

Week 45:
    * Project Start.
    * Created the schedule, the GitLab project and the table of contents.
    * Installed Ubuntu as a Virtual Machine running on top of Windows. Works very slowly. Discarded the idea of using Virtual Machines.
    
Week 46:
    * Malik came my home and helped me to setup Ubuntu. Installed Ubuntu as a boot OS. Now it properly works.
    * We found multiple lane videos, tutorials and codes. We picked one.
    * The code works 100% on given images and videos from original owner.

Week 47:
    * Worked on migrating the code from the static images to connect it with the camera.
    * Managed to set up ROS, openCV and Visual Studio. 
    * Managed to acces the webcam driver using uvcdynctrl and edit its parameters such as: contrast, brightness, etc. 
    * First time working in the LAS. Simon helped to set up ROS, rviz, and they gave me a tested webcam for me to program at home. It serves as a simulation tool.

Week 48:
    * Wrote the first "Hello World" Program. I can read the webcam data, write text, crop the image and run openCV code.
    * The team met at my home for everybody to install Ubuntu and make it work.
    * Discarded the camera calibration method of the original code. Using the OpenCV camera_calibration package instead.
    * Worked in the LAS. Run camera_calibration code for the first time in the webcam. It worked fine although it crashes when writing the output matrixes. Saved a .YML file in /temp folder to use the matrixes later.

Week 49:
    * Discovered that Ubuntu deletes everything in the /temp folder after restarting. My calibration files were gone.
    * Second time running the camera calibration in the LAS. It worked fine for the webcam. This time I managed to write the files in the camera. It is now shown in ROS node log.
    * Adjusted the files perspective_transform.py and load_parameters.py to include the new Warping Perspective and the Loading of parameters for the webcam.
    * Created a code for saving screenshots of the running node.
    
Week 50:
    * The code is now 100% working on the webcam pictures.
    * Worked alone in LAS. Tested the code on the real track. It works just as espected with a limited Field of View. I took a video testing it. 
    * This is the final simulation step with the camera. Now I switched to the real camera. Started fixing the code to adjust for this.

Week 51:
    * Met Simon in LAS. We made a new track.
    * We took a video from the onboard camera while running the ADAS across the track. This is a .bag file containing all the nodes information and using it as a Simulation.
    * We also discused ideas and our codes. 
    * Created a launch file and a .bash file. Now I don't have to open multiple terminals. Running a .bash file fromt the folder will start all the nodes and programs required.
     
Week 52 2019 and week 1 2020 (Holidays)
    * Deleted the original flag INTER_LINEAR in the Warping method. There are more options to explore in OpenCV warpPerspective.
    * Adjusted the Warping points to fit the new test video taken.
    * Discarded the yellow lines filter because we won't have yellow lines in the tracks. All of them are white only.
    * Discarded the original ranged thresholding for the white lines.
    * Modified the load_parameters.py file to transfer the save the source points and mode. Useful for visualizing the area that is going to be warped. 
    * I have been testing different thresholding techniques, including adaptative and gaussian adaptative.
    * The code can estimate the FPS needed. This should vary greatly deppending on the running CPU.
    * Locating the next box is currently done by the average mean of the current points. I've been working on changing this to make a linear fit and try to predict where to put the next Box.
    * The original code breaks down when there are no lines found. I fixed it by providing default lines and changing the lane color to red.
    * Added detailed screens to the main steps of the program. Now it can visualize 2x2, 3x3 or 4x4 screens. 
    * Generated jpeg images for the report (Camera Distortion, Warping and Threshold Comparison).
    * The code is 100% working on the test video. I created a video showing the results (Tests.mp4).
    * I have finished doing all I can do in the test video. Now I have to wait for Week 2 when the LAS is open again and start testing on the car.
    
Week 2:
    * Adjusted the code on the ADAS and now it is able to identify the lines and make a lane along the track.
    * Helped writing the report.

Week 3:
    * Helped making the presentation.